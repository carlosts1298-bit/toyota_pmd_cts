# Predictive Maintenance Challenge — Training Pipeline & Deployment Demo

## Metadata
- **Project**: Risk Specialist Technical Challenge — Predictive Maintenance
- **Author**: Carlos Torres Sánchez
- **Date**: September 2025
- **Python Version**: 3.11
- **Dataset**: [Microsoft Azure Predictive Maintenance (Kaggle)](https://www.kaggle.com/datasets/arnabbiswas1/microsoft-azure-predictive-maintenance)

---

## Overview
This repository contains an end-to-end ML solution for predicting machine failures using the **Microsoft Azure Predictive Maintenance** dataset.  
It includes:

- **EDA Notebook**: data exploration, quality checks, feature engineering insights.  
- **Training pipeline (`training_pipeline.py`)**:
  - Downloads raw data from Kaggle via `kagglehub`.
  - Builds **14-day rolling features** (telemetry ranges, error/maintenance counts, past failures).
  - Creates the binary target **`fail_next_14d`**.
  - Splits chronologically and trains a **Logistic Regression baseline**.
  - Exports metrics, figures, and the trained model.  
- **Deployment demo (`app.py`)**:
  - Minimal FastAPI service exposing the trained model.
  - REST endpoint `/predict` accepts JSON input and returns probabilities/predictions.

---

## Setup

### 1. Use system Python (recommended for Cloud Shell / quick start)

If your environment already has Python 3.9–3.12, create and activate a virtual environment:

```bash
python3 -V
python3 -m venv .venv
source .venv/bin/activate
```
Then install dependencies:

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

If you’re on Python 3.12 and any package fails to install due to version constraints, either:
  - bump that package to a 3.12-compatible release, or
  - use Python 3.11 (see optional steps below).

### 2. (Optional) Install Python 3.11 on Debian/Ubuntu (e.g., Google Cloud Shell)
If you need to pin Python to 3.11:
```bash
sudo apt-get update
sudo apt-get install -y software-properties-common
sudo add-apt-repository -y ppa:deadsnakes/ppa
sudo apt-get update
sudo apt-get install -y python3.11 python3.11-venv

```
Create and activate the environment with 3.11:
```bash
python3.11 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt

```
---

## Training Pipeline

### Run training

**Baseline configuration (Notebook reproduction)**  
Matches the notebook setup (L1 penalty, liblinear, balanced weights). Prioritizes recall.  

```bash
python src/training_pipeline.py \
  --output_dir artifacts/ \
  --test_size 0.2 \
  --random_state 42 \
  --class_weight balanced \
  --penalty l1 \
  --solver liblinear \
  --max_iter 3000 \
  --tol 1e-5
```

**Fast alternative (L2 + lbfgs)**
Quicker run with L2 + lbfgs. Useful for experiments and faster iterations.
```bash
python src/training_pipeline.py \
  --output_dir artifacts/ \
  --test_size 0.2 \
  --random_state 42 \
  --class_weight balanced \
  --penalty l2 \
  --solver lbfgs \
  --max_iter 200
```

**With winsorization (optional)**
Adds outlier capping (winsorization) for class 0. Recommended only for robustness checks.
```bash
python src/training_pipeline.py \
  --output_dir artifacts/ \
  --test_size 0.2 \
  --random_state 42 \
  --class_weight balanced \
  --penalty l2 \
  --solver lbfgs \
  --max_iter 200 \
  --winsor_class0 1 \
  --winsor_quantile 0.99
```

### Outputs
All artifacts will be saved under `artifacts/`:

- **Core models & preprocessing**  
  - `model.joblib` → trained logistic regression model  
  - `imputer.joblib` → median imputer used for numeric features  
  - `scaler.joblib` → standard scaler for numeric features  
  - `feature_names.json` → list of all feature names used in training  
  - `selected_features.json` → final subset of features after VIF + low-variance filtering  

- **Metrics & evaluation**  
  - `metrics.json` → performance metrics (AUC, KS, precision, recall, F1, confusion matrix)  
  - `roc_curve_test.png` → ROC curve on the test set  
  - `ks_curve_test.png` → KS curve on the test set  

- **Feature selection details** (under `feature_selection/`)  
  - `selected_features.csv` → final kept features  
  - `final_vif.csv` → VIF values after stepwise reduction  
  - `dropped_by_vif.csv` → features removed with their VIF at time of drop  

- **Optional (only if winsorization is enabled)**  
  - `ks_winsor_report.csv` → KS statistics before vs after winsorization  
  - `winsor_caps.json` → cap thresholds applied per feature  

---

## Deployment Demo

### Run FastAPI app
Ensure you have a trained model at `artifacts/model.joblib` (generated by the training pipeline).

```bash
uvicorn src.app:app --host 0.0.0.0 --port 8000
```

### Endpoints
- `GET /health` → service status.  
- `GET /metadata` → model metadata.  
- `POST /predict` → inference.

---

## Example payloads

We provide two illustrative payloads to test the `/predict` endpoint.  
They are derived from the model’s coefficients and scaler statistics:

**Note:** Run these `curl` commands in a **separate terminal** from the one where the FastAPI server is running (`uvicorn src.app:app --host 0.0.0.0 --port 8000`).  

- **Low-risk payload** → expected lower probability (often below threshold).  
- **High-risk payload** → expected higher probability (typically above threshold).  

### Low-risk payload
```bash
curl -s -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "threshold": 0.393,
    "records": [
      {
        "volt_mean_14d": 169.91333499880062,
        "volt_range_14d": 84.57459997514513,
        "volt_rstd_14d": 0.08728326618149061,
        "rotate_mean_14d": 450.0186468525399,
        "rotate_std_14d": 49.85422666265753,
        "rotate_range_14d": 283.8938460912428,
        "pressure_mean_14d": 99.90763924519406,
        "pressure_range_14d": 57.418241865763456,
        "vibration_mean_14d": 39.974622289274514,
        "vibration_range_14d": 28.494402336911058,
        "vibration_rstd_14d": 0.12433365448011392
      }
    ]
  }' | jq .
```
#### Low-risk payload expected output
```json
{
  "results": [
    {
      "proba": 0.17,
      "pred": 0,
      "message": "It is unlikely to fail in the next 14 days."
    }
  ]
}
```
### High-risk payload
```json
curl -s -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "threshold": 0.393,
    "records": [
      {
        "volt_mean_14d": 171.6666035804103,
        "volt_range_14d": 94.77913279332722,
        "volt_rstd_14d": 0.09273965152770773,
        "rotate_mean_14d": 443.1056670288406,
        "rotate_std_14d": 54.23875508936245,
        "rotate_range_14d": 319.97086925900277,
        "pressure_mean_14d": 101.81836325732122,
        "pressure_range_14d": 67.40058154096901,
        "vibration_mean_14d": 40.800575523541774,
        "vibration_range_14d": 32.7287028950147,
        "vibration_rstd_14d": 0.13667155075117418
      }
    ]
  }' | jq .
```
#### Low-risk payload expected output
```json
{
  "results": [
    {
      "proba": 0.76,
      "pred": 1,
      "message": "It will probably fail in the next 14 days."
    }
  ]
}
```

---

## Repository Structure
```
pdm-challenge/
├─ README.md
├─ requirements.txt
├─ src/
│  ├─ training_pipeline.py
│  └─ app.py
├─ notebooks/
│  └─ Microsoft_Azure_predictive_maintenance_EDA_Train.ipynb
├─ reports/
│  └─ short_tech_report.pdf
│  └─ Technical_design_document.pdf
└─ artifacts/                # created after running pipeline
```

## Deliverables

This repository includes all mandatory deliverables for the Risk Specialist Technical Challenge:

- **Exploratory Data Analysis Notebook** → [`notebooks/Microsoft_Azure_predictive_maintenance_EDA_Train.ipynb`](notebooks/Microsoft_Azure_predictive_maintenance_EDA_Train.ipynb)  
- **Technical Design Document** → [`reports/Technical_design_document.pdf`](reports/Technical_design_document.pdf)  
- **Short Tech Report** → [`reports/short_tech_report.pdf`](reports/short_tech_report.pdf)  
- **Training Pipeline** → [`src/training_pipeline.py`](src/training_pipeline.py)  
- **Deployment Demo (FastAPI)** → [`src/app.py`](src/app.py)  
